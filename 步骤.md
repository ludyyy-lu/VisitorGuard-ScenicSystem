# 环境基础
wsl的ubuntu22.04.5 LTS
在ubuntu中安装配置了zookeeper363、kafka_2.12-3.6.1、flink118、grafana、MySQL
使用了offset explore、DBeaver辅助工具
kafka -> flink -> mysql 数据传递链条通畅

# 功能实现

## 实时游客流量监控
### 编写\go-producer\main.go作为生产者。
### 编写flinksql代码
```
--  1. 创建 Kafka 源表 (Source Table),这张表代表了从 Kafka 'scenic_visitor_topic' topic流入的数据流。
CREATE TABLE kafka_visitor_events (
    `event_time` TIMESTAMP(3),  
    `area_id`    STRING,        
    `action`     STRING,        
    `user_id`    STRING,        
    WATERMARK FOR `event_time` AS `event_time` - INTERVAL '5' SECOND
) WITH (
    'connector' = 'kafka',
    'topic' = 'scenic_visitor_topic',
    'properties.bootstrap.servers' = '172.23.79.129:9092', 
    'properties.group.id' = 'visitor_guard_consumer', 
    'scan.startup.mode' = 'latest-offset',            
    'json.timestamp-format.standard' = 'ISO-8601',
    'format' = 'json'                                 
);


--  2. 创建 MySQL 目标表 (Sink Table)
CREATE TABLE mysql_sink_area_stats (
    `area_id`         VARCHAR(255) NOT NULL,
    `current_visitors` BIGINT,
    PRIMARY KEY (`area_id`) NOT ENFORCED -- 告诉 Flink area_id 是主键
) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:mysql://172.23.79.129:3306/bigdata?serverTimezone=UTC', 
    'table-name' = 'area_realtime_stats',
    'username' = 'remote_user',
    'password' = 'Admin@123'
);

--  创建 MySQL 目标表 (Sink) 用于存储每分钟出入流量
CREATE TABLE mysql_sink_traffic_stats (
    `area_id`         VARCHAR(255) NOT NULL,
    `window_end`      TIMESTAMP(3) NOT NULL,
    `in_count`        BIGINT,
    `out_count`       BIGINT,
    PRIMARY KEY (`area_id`, `window_end`) NOT ENFORCED,
    WATERMARK FOR `window_end` AS `window_end` - INTERVAL '1' SECOND  
) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:mysql://172.23.79.129:3306/bigdata?serverTimezone=UTC',
    'table-name' = 'area_traffic_per_minute',
    'username' = 'remote_user',
    'password' = 'Admin@123'
);

--  实时统计各区域当前游客数 (已修复负数问题)
INSERT INTO mysql_sink_area_stats
SELECT
    area_id,
    GREATEST(CAST(0 AS BIGINT), SUM(CASE `action` WHEN 'in' THEN 1 ELSE -1 END)) AS current_visitors
FROM
    kafka_visitor_events
GROUP BY
    area_id;

INSERT INTO mysql_sink_traffic_stats
SELECT
    area_id,
    TUMBLE_END(event_time, INTERVAL '1' MINUTE) AS window_end,
    COUNT(CASE `action` WHEN 'in' THEN 1 ELSE NULL END) AS in_count,
    COUNT(CASE `action` WHEN 'out' THEN 1 ELSE NULL END) AS out_count
FROM
    kafka_visitor_events
GROUP BY
    area_id,
    TUMBLE(event_time, INTERVAL '1' MINUTE);

```
### 编写MySQL代码

```
--  area_realtime_stats用来存储每个区域的实时游客数量
CREATE TABLE area_realtime_stats (
    area_id VARCHAR(255) NOT NULL,   
    current_visitors BIGINT,        
    PRIMARY KEY (area_id)        
);


-- 这个表将记录每个区域在每个时间窗口的出入人次。
CREATE TABLE area_traffic_per_minute (
    area_id VARCHAR(255) NOT NULL,
    window_end TIMESTAMP(3) NOT NULL,  -- 统计窗口的结束时间
    in_count BIGINT,                   -- 该窗口内进入的人次
    out_count BIGINT,                  -- 该窗口内离开的人次
    PRIMARY KEY (area_id, window_end)  
);
```
### 创建grafana面板
1. 面板1 - 景区游客总数
添加visualization，选择stat（统计图）
添加sql语句：
```
SELECT SUM(current_visitors) FROM area_realtime_stats;
```
2. 面板2 - 各区实时人数
添加visualization，选择Bar gauge（条形表）
添加sql语句：
```
SELECT area_id, current_visitors FROM area_realtime_stats ORDER BY area_id;
```
在右侧面板设置中，找到 Thresholds。
你可以设置阈值来改变颜色。例如：
Base: 0 (绿色)
80: 黄色 (代表舒适度下降)
100: 红色 (代表拥挤)

3. 面板3 - 各区域出入流量趋势
添加visualization，选择 Time series (时间序列图)
添加sql语句：
```
-- 用的这个，但是似乎是全区的进出，而不是各个区域的进出人数
SELECT
  window_end AS "time",
  area_id,
  in_count,
  out_count
FROM
  area_traffic_per_minute
WHERE
  $__timeFilter(window_end)
ORDER BY
  window_end ASC

-- 这个也不对
-- 查询所有“进入”的流量
SELECT
  window_end AS "time",
  -- 将区域名和“进入”拼接成一个唯一的指标名称
  CONCAT(area_id, ' - 进入') AS metric,
  in_count AS value
FROM
  area_traffic_per_minute
WHERE
  $__timeFilter(window_end)

UNION ALL  -- 将上下两个查询的结果合并起来

-- 查询所有“离开”的流量
SELECT
  window_end AS "time",
  -- 将区域名和“离开”拼接成一个唯一的指标名称
  CONCAT(area_id, ' - 离开') AS metric,
  out_count AS value
FROM
  area_traffic_per_minute
WHERE
  $__timeFilter(window_end)

-- 按时间排序，让图表正确显示
ORDER BY
  time ASC;
```
**Save dashboard**

截至目前已完成：
* 全域总览： 实时计算并展示整个景区的当前总游客人数。
* 分区统计： 实时计算并展示景区内各个核心景点或区域（如A门、B展馆、C山顶）的当前游客人数。
* 出入流量统计： 按时间窗口（如每分钟）统计整个景区及各分区的进入人次和离开人次。
### 暂未解决的问题
1. 时区错位
2. 各区出入流量 -> 全区出入流量 这里没分区成功

## 游客饱和度预警
### 编写flinksql代码
```
-- 这是一张维表 (Dimension Table)，它的数据是静态的，用于关联查询
CREATE TABLE mysql_dim_thresholds (
    `area_id` VARCHAR(255) NOT NULL,
    `comfort_threshold` INT,
    `warning_threshold` INT,
    `alert_threshold` INT,
    PRIMARY KEY (area_id) NOT ENFORCED
) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:mysql://172.23.79.129:3306/bigdata?serverTimezone=UTC',
    'table-name' = 'area_thresholds',
    'username' = 'remote_user', 
    'password' = 'Admin@123'    
);

--  创建 MySQL 目标表 (Sink) 用于存储各区域当前最新报警 (最终版)
CREATE TABLE mysql_sink_current_alert (
    `area_id` VARCHAR(255) NOT NULL,
    `last_alert_time` TIMESTAMP(3),
    `current_visitors` BIGINT,
    `alert_level` VARCHAR(50),
    `alert_message` VARCHAR(512),
    PRIMARY KEY (area_id) NOT ENFORCED
) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:mysql://172.23.79.129:3306/bigdata?serverTimezone=UTC',
    'table-name' = 'area_current_alert', 
    'username' = 'remote_user',
    'password' = 'Admin@123'
);

-- 在包含了阈值信息的流上进行最终判断和筛选
INSERT INTO mysql_sink_current_alert
SELECT
    area_id, 
    LOCALTIMESTAMP AS last_alert_time, 
    current_visitors,
    CASE
        WHEN current_visitors > alert_threshold THEN '红色警戒'
        ELSE '黄色拥堵'
    END AS alert_level,
    CONCAT(
        '【', CASE WHEN current_visitors > alert_threshold THEN '红色警戒' ELSE '黄色拥堵' END, '】区域: ', area_id,
        ', 当前人数: ', CAST(current_visitors AS STRING),
        ', 已超过阈值: ', CASE WHEN current_visitors > alert_threshold THEN CAST(alert_threshold AS STRING) ELSE CAST(warning_threshold AS STRING) END,
        '人, 请相关人员注意！'
    ) AS alert_message
FROM
    visitors_with_hardcoded_thresholds
WHERE
    current_visitors > warning_threshold;
```
### 编写MySQL代码
```
-- 创建预警规则表
CREATE TABLE area_thresholds (
    area_id VARCHAR(255) NOT NULL PRIMARY KEY,
    -- '舒适'状态下的最大人数
    comfort_threshold INT,
    -- 超过这个值就进入'拥挤'状态
    warning_threshold INT,
    -- 超过这个值就进入'警戒'状态，需要立即干预
    alert_threshold INT
);

-- 插入预警规则数据
INSERT INTO area_thresholds (area_id, comfort_threshold, warning_threshold, alert_threshold) VALUES
('好莱坞大道', 80, 100, 120),
('哈利波特的魔法世界', 150, 180, 200),
('小黄人乐园', 100, 120, 150),
('侏罗纪世界大冒险', 200, 250, 300),
('变形金刚基地', 180, 220, 250); 

-- 创建一个名为 area_current_alert 的新表，它代表**“每个区域当前的最新报警状态”**。这张表有主键，可以被 Flink 更新。
CREATE TABLE area_current_alert (
    area_id VARCHAR(255) NOT NULL PRIMARY KEY, 
    last_alert_time DATETIME(3),         
    current_visitors BIGINT,
    alert_level VARCHAR(50),
    alert_message VARCHAR(512)
);
```
### 创建grafana面板
1. 面板1 - 当前告警状态
添加visualization，选择Table (表格) 
添加sql语句：
```
SELECT
  last_alert_time AS "最近报警时间",
  area_id AS "报警区域",
  alert_level AS "报警级别",
  current_visitors AS "当前人数",
  alert_message AS "报警详情"
FROM
  area_current_alert
ORDER BY
  last_alert_time DESC
```

**Save dashboard**

是不是已经完成了，似乎是的，
不对，预警升级好像没做
* 阈值设定： 系统可以为整个景区及每个分区设定不同的游客容量阈值（如：舒适、拥挤、警戒）。
* 实时预警： 当某个区域的实时游客数超过预设的阈值时，系统立即生成一条预警信息。例如，“C山顶当前人数已达8500，超过警戒阈值8000，请启动限流措施！”。
* 预警升级： 可以设计多级预警机制，例如，超过“拥挤”阈值时为黄色预警，超过“警戒”阈值时为红色预警。

### 暂未解决的问题
1. grafana不会设置表设置，想设计好看点不会设置
2. grafana不会设置alerting，按理说饱和度预警用报警功能很合适，奈何我不会
3. 似乎还是会统计出负数，不知道是代码没写对，还是旧数据在捣蛋

## 游客行为分析：
### 编写flinksql代码
```
-- 创建 MySQL 目标表 (Sink) 用于存储游客逗留时长
CREATE TABLE mysql_sink_stay_duration (
    `user_id` VARCHAR,
    `area_id` VARCHAR,
    `entry_time` TIMESTAMP(3),
    `exit_time` TIMESTAMP(3),
    `duration_minutes` BIGINT
) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:mysql://172.23.79.129:3306/bigdata?serverTimezone=UTC',
    'table-name' = 'visitor_stay_duration',
    'username' = 'remote_user', 
    'password' = 'Admin@123'    
);

-- 使用 MATCH_RECOGNIZE 计算游客逗留时长
INSERT INTO mysql_sink_stay_duration
SELECT
    user_id,
    area_id,
    entry_time,
    exit_time,
    TIMESTAMPDIFF(MINUTE, entry_time, exit_time) AS duration_minutes
FROM
    kafka_visitor_events
    MATCH_RECOGNIZE (
        PARTITION BY user_id, area_id
        ORDER BY event_time
        MEASURES
            a.event_time AS entry_time,
            b.event_time AS exit_time
        ONE ROW PER MATCH
        AFTER MATCH SKIP TO NEXT ROW
        PATTERN (a b)
        DEFINE
            a AS a.action = 'in',
            b AS b.action = 'out'
    );

-- 创建 MySQL 目标表 (Sink) 用于存储游客移动路径
CREATE TABLE mysql_sink_route_log (
    `user_id` VARCHAR,
    `from_area` VARCHAR,
    `to_area` VARCHAR,
    `route_time` TIMESTAMP(3),
    `travel_time_minutes` BIGINT
) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:mysql://172.23.79.129:3306/bigdata?serverTimezone=UTC',
    'table-name' = 'visitor_route_log',
    'username' = 'remote_user', 
    'password' = 'Admin@123'    
);

-- 使用 MATCH_RECOGNIZE 分析热门游客路线
INSERT INTO mysql_sink_route_log
SELECT
    user_id,
    from_area,
    to_area,
    route_time,
    travel_time_minutes
FROM
    kafka_visitor_events
    MATCH_RECOGNIZE (
        PARTITION BY user_id
        ORDER BY event_time
        MEASURES
            a.area_id AS from_area,
            b.area_id AS to_area,
            b.event_time AS route_time,
            TIMESTAMPDIFF(MINUTE, a.event_time, b.event_time) AS travel_time_minutes
        ONE ROW PER MATCH
        AFTER MATCH SKIP TO NEXT ROW
        PATTERN (a b)
        DEFINE
            a AS a.action = 'out',
            b AS b.action = 'in' AND b.area_id <> a.area_id
    );
```
### 编写MySQL代码
```
-- 存储每个游客在每个区域的逗留时长记录
CREATE TABLE visitor_stay_duration (
    user_id VARCHAR(255),
    area_id VARCHAR(255),
    entry_time DATETIME(3),   -- 进入时间
    exit_time DATETIME(3),    -- 离开时间
    duration_minutes BIGINT    -- 逗留时长（分钟）
);

-- 存储所有被识别出的游客移动路径
CREATE TABLE visitor_route_log (
    user_id VARCHAR(255),
    from_area VARCHAR(255),  
    to_area VARCHAR(255),    
    route_time DATETIME(3),  
    travel_time_minutes BIGINT 
);
```
### 创建grafana面板
1. 面板1 - 各区域平均逗留时长
添加visualization，选择Bar chart
添加sql语句：
```
-- 这个查询会按区域 (area_id) 分组，并计算每个区域 duration_minutes 的平均值
SELECT
  AVG(duration_minutes) AS "avg_duration",
  area_id AS "metric"
FROM
  visitor_stay_duration
GROUP BY
  area_id
ORDER BY
  avg_duration DESC
```
2. 面板2 - 游客逗留时长分布
添加visualization，选择Histogram
添加sql语句：
```
SELECT
  duration_minutes
FROM
  visitor_stay_duration
WHERE
  -- 加上时间过滤器，可以只分析某个时间段内的游客行为
  $__timeFilter(exit_time)
```
3. 面板3 - 热门路线分析
添加visualization，选择Bar chart
添加sql语句：
```
SELECT
  -- 将起点和终点拼接成路线名称
  CONCAT(from_area, ' -> ', to_area) AS "route",
  -- 使用 COUNT(*) 统计路线出现的次数
  COUNT(*) as "count"
FROM
  visitor_route_log
WHERE
  $__timeFilter(route_time)
GROUP BY
  route
ORDER BY
  count DESC
LIMIT 10;
```

**Save dashboard**

该模块已完成：
* 平均逗留时长： 分析游客在整个景区或特定景点的平均游玩时间。
* 热门路线分析： 通过分析游客在不同景点的出入顺序，发现最受欢迎的游览路线。

### 暂未解决的问题
1. 此处再次重申时区的问题，虚拟机里面是CST但是我都设置成UTC了，可能是这个错误，回头再看看。
2. 本项目分析的问题较多，flink需要同时运行多个task，我在做的时候遇到了资源不足task运行失败的问题。可以通过修改flink配置文件解决，但是我还没改。

# grafana报警未配置成功，亟待解决

# 其他信息
我不确定我配置的对不对：
![alt text](image.png)

配置好的仪表盘：
![alt text](image-1.png)


我目前遇到了一个问题，
这是程序终端打印的输出
```
2025/07/15 20:47:27 成功发送消息: {"event_time":"2025-07-15T12:47:26.256","area_id":"变形金刚基地","action":"out","user_id":"user-6715"}
2025/07/15 20:47:29 成功发送消息: {"event_time":"2025-07-15T12:47:28.032","area_id":"好莱坞大道","action":"out","user_id":"user-9458"}
2025/07/15 20:47:31 成功发送消息: {"event_time":"2025-07-15T12:47:30.001","area_id":"哈利波特的魔法世界","action":"in","user_id":"user-8836"}
```
这是MySQL存的时间：
```
小黄人乐园	2025-07-14 22:43:00	5	1
小黄人乐园	2025-07-14 22:44:00	3	5
小黄人乐园	2025-07-15 03:55:00	2	0
小黄人乐园	2025-07-15 04:45:00	1	2
小黄人乐园	2025-07-15 04:46:00	8	1
小黄人乐园	2025-07-15 04:47:00	2	2
```
为什么有这么大的时差，目前没有解决。
看班只能读MySQL里面的有偏差的时间
![alt text](image-2.png)

ludy@LAPTOP-FAOM7SQ7:~/kafka/kafka_2.12-3.6.1$ date
Wed Jul 16 09:30:08 CST 2025


## 功能实现
## 游客饱和预警
1. 创建“规则库”： 在 MySQL 中创建一张表，用来存放每个区域的预警阈值。
2. 创建“警报日志”： 在 MySQL 中创建另一张表，用来记录所有触发的警报信息。
3. 编写“预警规则引擎”： 在 Flink SQL 中编写核心的预警逻辑，这是最关键的一步。

游客预警的面板没调好，，，不会调，我服了。

## 游客行为分析
### 计算游客在各个景点的平均逗留时长

要计算逗留时长，我们必须能够精确地识别出同一个游客，在同一个区域，完成了一次完整的“进入”和“离开”行为。

CREATE TABLE visitor_stay_duration (
    user_id VARCHAR(255),
    area_id VARCHAR(255),
    entry_time DATETIME(3),   -- 进入时间
    exit_time DATETIME(3),    -- 离开时间
    duration_minutes BIGINT    -- 逗留时长（分钟）
);

flinksql：
CREATE TABLE mysql_sink_stay_duration (
    `user_id` VARCHAR,
    `area_id` VARCHAR,
    `entry_time` TIMESTAMP(3),
    `exit_time` TIMESTAMP(3),
    `duration_minutes` BIGINT
) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:mysql://172.23.79.129:3306/bigdata?serverTimezone=UTC',
    'table-name' = 'visitor_stay_duration',
    'username' = 'remote_user', -- 替换为你的用户名
    'password' = 'Admin@123'    -- 替换为你的密码
);


我们将创建两个新的面板：
面板一：各区域平均逗留时长（排行榜）
这个面板会清晰地展示出哪个景点的“粘性”最强，游客最愿意花时间。我们将使用一个条形图 (Bar chart) 来制作排行榜。
面板二：游客逗留时长分布（直方图）
这个面板可以帮助我们了解游客的普遍行为模式。比如，大多数游客的游玩时长是集中在 10-20 分钟，还是 30-60 分钟？这对于评估项目吸引力和优化游客体验非常重要。我们将使用一个直方图 (Histogram) 来实现。



## 热门路线分析
这个功能的实现，将真正体现出 Flink 复杂事件处理 (CEP) 的威力，让我们的系统能够从单个景点的分析，跃升到对游客流动路径的深层洞察。

**目标与价值**
我们的目标是识别出游客在景区中最常走的连续路径。例如，我们想知道：
从“好莱坞大道”离开后，去“侏罗纪世界大冒险”的游客多，还是去“小黄人乐园”的游客多？
是否存在一条经典的“三步走”路线，比如 A -> B -> C？
这些信息对于优化景区布局、设置引导标识、安排商业网点、疏导人流都具有极高的战略价值。
**技术挑战：识别跨区域的事件序列**
要实现这个功能，我们需要识别一个比“进入-离开”更复杂的模式：
“同一个游客，在 A 区域有一个‘离开(out)’事件，紧接着在 B 区域有一个‘进入(in)’事件，并且这两个事件之间的时间间隔不能太长（比如不能超过30分钟）。”
我们将再次使用 MATCH_RECOGNIZE，但这次的 PATTERN 会更复杂，涉及到连续两个不同事件的匹配。

USE bigdata; -- 或你的数据库名

CREATE TABLE visitor_route_log (
    user_id VARCHAR(255),
    from_area VARCHAR(255),  -- 起点区域
    to_area VARCHAR(255),    -- 终点区域
    route_time DATETIME(3),  -- 到达终点区域的时间
    travel_time_minutes BIGINT -- 在两个区域之间的移动耗时（分钟）
);

CREATE TABLE mysql_sink_route_log (
    `user_id` VARCHAR,
    `from_area` VARCHAR,
    `to_area` VARCHAR,
    `route_time` TIMESTAMP(3),
    `travel_time_minutes` BIGINT
) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:mysql://172.23.79.129:3306/bigdata?serverTimezone=UTC',
    'table-name' = 'visitor_route_log',
    'username' = 'remote_user', -- 替换为你的用户名
    'password' = 'Admin@123'    -- 替换为你的密码
);


INSERT INTO mysql_sink_route_log
SELECT
    user_id,
    from_area,
    to_area,
    route_time,
    travel_time_minutes
FROM
    kafka_visitor_events
    MATCH_RECOGNIZE (
        -- PARTITION BY 只按 user_id 分区，因为我们要追踪同一个游客在不同区域间的移动
        PARTITION BY user_id
        ORDER BY event_time
        MEASURES
            -- a.area_id 就是起点区域的名称
            a.area_id AS from_area,
            -- b.area_id 就是终点区域的名称
            b.area_id AS to_area,
            -- b.event_time 就是这条移动路径的发生时间（即到达B点的时间）
            b.event_time AS route_time,
            -- 计算两个事件的时间差作为移动耗时
            TIMESTAMPDIFF(MINUTE, a.event_time, b.event_time) AS travel_time_minutes
        ONE ROW PER MATCH
        AFTER MATCH SKIP TO NEXT ROW
        -- 定义核心模式：一个 'out' 事件，紧跟着一个 'in' 事件
        PATTERN (a b)
        DEFINE
            -- 事件 a 必须是 'out'
            a AS a.action = 'out',
            -- 事件 b 必须是 'in'，并且它的区域不能和 a 的区域相同
            b AS b.action = 'in' AND b.area_id <> a.area_id
    );


这个查询的精妙之处：
PARTITION BY user_id：我们不再按 area_id 分区，因为我们关心的就是跨区域的移动。
PATTERN (a b)：模式依然是两个连续事件 a 和 b。
DEFINE 子句：
a AS a.action = 'out'：第一个事件 a 必须是离开某个区域。
b AS b.action = 'in' AND b.area_id <> a.area_id：第二个事件 b 必须是进入某个区域，并且我们通过 b.area_id <> a.area_id 这个条件，排除了“离开A点又马上进入A点”这种无意义的数据。

SELECT * FROM visitor_route_log ORDER BY route_time DESC LIMIT 10;


好像大体完成了，有一些遗留问题
时区还没配置好
flink不能同时运行那么多task
我的面板乱糟糟，看的人心烦